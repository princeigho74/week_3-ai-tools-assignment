# AI Tools Assignment: Complete Implementation

A comprehensive evaluation of AI frameworks (TensorFlow, PyTorch, Scikit-learn, spaCy) covering theoretical understanding, practical implementation, ethics, and deployment.

## ğŸ“‹ Project Overview

This assignment demonstrates proficiency across three major areas:

### **Part 1: Theoretical Understanding**
- Comparison of TensorFlow vs PyTorch vs Scikit-learn
- Framework selection criteria and use cases
- In-depth analysis of Jupyter Notebooks and spaCy

### **Part 2: Practical Implementation**
- **Task 1:** Iris species classification with Decision Trees (Scikit-learn)
- **Task 2:** MNIST handwritten digit classification with CNN (TensorFlow)
- **Task 3:** Amazon reviews sentiment analysis & NER (spaCy)

### **Part 3: Ethics & Optimization**
- Bias identification and mitigation strategies
- Debugging common deep learning errors
- Model optimization techniques
- TensorFlow Fairness analysis

### **Bonus: Model Deployment**
- Streamlit web application for MNIST classifier
- Interactive drawing canvas
- Performance dashboard

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- pip or conda

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/ai-tools-assignment.git
cd ai-tools-assignment

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Download spaCy model
python -m spacy download en_core_web_sm
```

### Run Individual Tasks

```bash
# Task 1: Iris Classification
python Part2_Task1_Iris.py

# Task 2: MNIST Classification
python Part2_Task2_MNIST.py

# Task 3: NLP Sentiment Analysis
python Part2_Task3_NLP.py

# Part 3: Ethics Analysis
python Part3_Ethics.py

# Streamlit App (Bonus)
streamlit run Bonus_Streamlit_App.py
# Access at: http://localhost:8501
```

---

## ğŸ“ Project Structure

```
ai-tools-assignment/
â”‚
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ AI_Tools_Assignment_Report.pdf     # Complete report (in reports/)
â”‚
â”œâ”€â”€ Part1_Theoretical.md               # Theoretical answers
â”‚
â”œâ”€â”€ Part2_Task1_Iris.py               # Classical ML - Scikit-learn
â”œâ”€â”€ Part2_Task2_MNIST.py              # Deep Learning - TensorFlow
â”œâ”€â”€ Part2_Task3_NLP.py                # NLP - spaCy
â”‚
â”œâ”€â”€ Part3_Ethics.py                   # Ethics & Optimization
â”‚
â”œâ”€â”€ Bonus_Streamlit_App.py            # Web deployment
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ iris.csv                      # Iris dataset
â”‚   â”œâ”€â”€ amazon_reviews.txt            # Sample reviews
â”‚   â””â”€â”€ mnist_test_samples.npy        # MNIST test samples
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ mnist_model.h5                # Trained MNIST CNN
â”‚   â””â”€â”€ iris_model.pkl                # Trained Iris classifier
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ Task1_Iris_EDA.ipynb          # Exploratory analysis
â”‚   â”œâ”€â”€ Task2_MNIST_Training.ipynb    # Model training
â”‚   â””â”€â”€ Task3_NLP_Analysis.ipynb      # Sentiment analysis
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ AI_Tools_Assignment_Report.pdf
â”‚   â”œâ”€â”€ screenshots/                  # Model output screenshots
â”‚   â”‚   â”œâ”€â”€ iris_cm.png
â”‚   â”‚   â”œâ”€â”€ mnist_accuracy.png
â”‚   â”‚   â”œâ”€â”€ sentiment_analysis.png
â”‚   â”‚   â””â”€â”€ streamlit_app.png
â”‚   â””â”€â”€ bias_analysis.md
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ SETUP.md                      # Detailed setup instructions
    â”œâ”€â”€ USAGE.md                      # How to use each component
    â””â”€â”€ TROUBLESHOOTING.md            # Common issues and fixes
```

---

## ğŸ“Š Results Summary

### Task 1: Iris Classification (Scikit-learn)
```
Decision Tree Classifier
â”œâ”€â”€ Test Accuracy:  96.67%
â”œâ”€â”€ Test Precision: 96.67%
â”œâ”€â”€ Test Recall:    96.67%
â””â”€â”€ Status: âœ“ PASSED
```

### Task 2: MNIST Classification (TensorFlow)
```
CNN Model
â”œâ”€â”€ Test Accuracy:  98.50%
â”œâ”€â”€ Requirement:    >95%
â””â”€â”€ Status: âœ“ EXCEEDED (98.50% > 95%)
```

### Task 3: NLP Sentiment Analysis (spaCy)
```
Sentiment Analysis Results
â”œâ”€â”€ Reviews analyzed: 10
â”œâ”€â”€ Entities extracted: 15
â”œâ”€â”€ Unique products: 8
â”œâ”€â”€ Unique brands: 5
â”œâ”€â”€ Sentiment distribution:
â”‚   â”œâ”€â”€ Positive: 60%
â”‚   â”œâ”€â”€ Negative: 20%
â”‚   â””â”€â”€ Neutral:  20%
â””â”€â”€ Status: âœ“ COMPLETED
```

---

## ğŸ” Part 1: Theoretical Understanding

### TensorFlow vs PyTorch Comparison

| Aspect | TensorFlow | PyTorch |
|--------|-----------|---------|
| Computation Graph | Static (TF 2.x: dynamic) | Dynamic (define-by-run) |
| Learning Curve | Steeper | Gentle, Pythonic |
| Production Support | Excellent | Growing |
| Research Use | Good | Excellent |
| Deployment Tools | Comprehensive | Basic |

### Framework Recommendations

**Use TensorFlow when:**
- Building production systems at scale
- Deploying to mobile/edge devices
- Working with existing TF infrastructure
- Needing comprehensive deployment tools

**Use PyTorch when:**
- Conducting research
- Prototyping quickly
- Building custom architectures
- Prioritizing code clarity

---

## ğŸ› ï¸ Part 3: Ethics & Optimization

### Identified Biases in MNIST

1. **Distribution Bias:** Slight class imbalance (1.24x ratio)
2. **Representation Bias:** Limited to US postal service data
3. **Demographic Bias:** Single demographic source
4. **Temporal Bias:** Data from 1990s

### Mitigation Strategies

âœ“ Data augmentation (rotation, scaling, elastic deformation)  
âœ“ Stratified cross-validation  
âœ“ Multiple dataset sources (EMNIST, IAM, Chars74K)  
âœ“ Per-class fairness monitoring  
âœ“ TensorFlow Fairness Indicators  

### Common Bugs Fixed

| Bug | Error | Fix |
|-----|-------|-----|
| Wrong input shape | ValueError on layer input | Flatten images first |
| Wrong activation | Poor convergence | Use softmax for multi-class |
| Loss-target mismatch | Shape incompatibility | Match loss to label format |
| Dimension mismatch | Input shape error | Reshape/flatten data |

---

## ğŸŒ Bonus: Streamlit Deployment

### Features

1. **Draw Mode**
   - Canvas-based digit input
   - Real-time prediction
   - Example gallery

2. **Upload Mode**
   - Image file support
   - Auto-preprocessing
   - Confidence scores

3. **Model Info**
   - Architecture details
   - Training parameters
   - Summary statistics

4. **Performance Dashboard**
   - Overall metrics
   - Per-digit accuracy
   - Confusion matrix
   - Error analysis

### Running the App

```bash
streamlit run Bonus_Streamlit_App.py
```

Then navigate to `http://localhost:8501` in your browser.

---

## ğŸ“š Key Learnings

### Machine Learning
- Data preprocessing and standardization importance
- Train/test split for unbiased evaluation
- Feature importance analysis
- Confusion matrix interpretation

### Deep Learning
- CNN architecture design (conv â†’ pool â†’ flatten â†’ dense)
- Activation functions (ReLU, softmax)
- Dropout regularization
- Training monitoring and early stopping

### NLP
- Named Entity Recognition (NER)
- Tokenization and lemmatization
- Sentiment analysis (rule-based approach)
- Domain-specific text processing

### AI Ethics
- Bias identification in datasets
- Fairness metrics and monitoring
- Mitigation strategies
- Responsible AI deployment

---

## ğŸ“ Files to Submit (GitHub)

**Code Files:**
- âœ“ Part1_Theoretical.md
- âœ“ Part2_Task1_Iris.py
- âœ“ Part2_Task2_MNIST.py
- âœ“ Part2_Task3_NLP.py
- âœ“ Part3_Ethics.py
- âœ“ Bonus_Streamlit_App.py

**Documentation:**
- âœ“ README.md
- âœ“ requirements.txt
- âœ“ SETUP.md
- âœ“ docs/

**Notebooks:**
- âœ“ notebooks/Task1_Iris_EDA.ipynb
- âœ“ notebooks/Task2_MNIST_Training.ipynb
- âœ“ notebooks/Task3_NLP_Analysis.ipynb

**Report & Outputs:**
- âœ“ AI_Tools_Assignment_Report.pdf (in reports/)
- âœ“ Screenshots (in reports/screenshots/)

---

## ğŸ”— GitHub Setup

```bash
# Initialize git repository
git init
git add .
git commit -m "Initial commit: AI Tools Assignment"

# Add remote repository
git remote add origin https://github.com/yourusername/ai-tools-assignment.git

# Push to GitHub
git branch -M main
git push -u origin main
```

## ğŸ“‹ Checklist for Submission

- [ ] All Python scripts are well-commented
- [ ] requirements.txt is complete and tested
- [ ] README.md contains clear instructions
- [ ] All code runs without errors
- [ ] Notebooks are clean and reproducible
- [ ] PDF report generated and saved
- [ ] Screenshots taken and saved
- [ ] GitHub repository is public and linked
- [ ] Commit history is meaningful
- [ ] All files are pushed to GitHub


## ğŸ› Troubleshooting

### Common Issues

**Issue: `ModuleNotFoundError: No module named 'tensorflow'`**
```bash
pip install --upgrade tensorflow
```

**Issue: `No module named 'spacy'`**
```bash
pip install spacy
python -m spacy download en_core_web_sm
```

**Issue: CUDA/GPU not found**
```bash
# Use CPU-only version (slower but works)
pip install tensorflow-cpu
```

**Issue: Streamlit not running**
```bash
pip install --upgrade streamlit
streamlit run Bonus_Streamlit_App.py --logger.level=debug
```

See `docs/TROUBLESHOOTING.md` for more solutions.


## ğŸ“– Additional Resources

### Official Documentation
- [TensorFlow Documentation](https://www.tensorflow.org/)
- [PyTorch Documentation](https://pytorch.org/)
- [Scikit-learn Guide](https://scikit-learn.org/)
- [spaCy Documentation](https://spacy.io/)

### Datasets
- [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)
- [Kaggle Datasets](https://www.kaggle.com/datasets)
- [TensorFlow Datasets](https://www.tensorflow.org/datasets)

### Ethics & Fairness
- [TensorFlow Fairness Indicators](https://www.tensorflow.org/fairness/indicators)
- [AI Ethics Guidelines](https://www.ai.gov/ai-policy/u-s-ai-standards/)
- [Machine Learning Bias](https://research.google/pubs/fair-machine-learning/)

### Learning Materials
- [Deep Learning Specialization](https://www.deeplearning.ai/)
- [Fast.ai Courses](https://www.fast.ai/)
- [Papers with Code](https://paperswithcode.com/)

---

## ğŸ’¡ Tips for Success

### Best Practices
1. **Comment your code extensively** - future maintainers will thank you
2. **Test each component independently** - catch bugs early
3. **Document assumptions** - make your thinking clear
4. **Use meaningful variable names** - improve code readability
5. **Create reproducible notebooks** - others should run your code

### Code Quality Checklist
- [ ] Functions have docstrings
- [ ] Variable names are descriptive
- [ ] Code is DRY (Don't Repeat Yourself)
- [ ] Error handling is implemented
- [ ] Comments explain the "why" not the "what"
- [ ] Code follows PEP 8 style guide


## ğŸ“ Support & Contact

For questions or issues:
1. Check `docs/TROUBLESHOOTING.md`
2. Review code comments in relevant files
3. Check official documentation links
4. Post issues on GitHub


## ğŸ“„ License

This project is submitted as an academic assignment. Use responsibly.

---

## ğŸ“ Academic Integrity

This is original work prepared as part of coursework. When using this as reference:
- Cite appropriately in your work
- Don't directly copy code without modification
- Learn from the approach and implement your own solution
- Understand the concepts before using them


## ğŸ† Assignment Completion Status

- [x] **Part 1: Theoretical Understanding**
  - [x] Q1: TensorFlow vs PyTorch
  - [x] Q2: Jupyter Notebook use cases
  - [x] Q3: spaCy enhancements
  - [x] Comparative analysis table

- [x] **Part 2: Practical Implementation**
  - [x] Task 1: Iris Classification (Scikit-learn) - âœ“ 96.67% accuracy
  - [x] Task 2: MNIST Classification (TensorFlow) - âœ“ 98.50% accuracy (>95%)
  - [x] Task 3: NLP Sentiment Analysis (spaCy) - âœ“ Complete

- [x] **Part 3: Ethics & Optimization**
  - [x] Bias identification in MNIST
  - [x] Mitigation strategies
  - [x] Buggy code debugging
  - [x] Optimization techniques
  - [x] Fairness report

- [x] **Bonus: Model Deployment**
  - [x] Streamlit web application
  - [x] Drawing interface
  - [x] Performance dashboard
  - [x] Upload functionality


## ğŸ“Š Statistics

```
Total Lines of Code:     ~2,500
Number of Scripts:       6
Jupyter Notebooks:       3
Models Trained:          3
Datasets Used:           3 (Iris, MNIST, Amazon Reviews)
Accuracy Achieved:       98.50% (MNIST), 96.67% (Iris)
Ethical Issues Identified: 4
Mitigation Strategies:   8+
Deployment Options:      5+
```

---

## ğŸ¯ Learning Objectives Achieved

âœ“ Understand differences between AI frameworks  
âœ“ Select appropriate tools for different problems  
âœ“ Preprocess and prepare data effectively  
âœ“ Build and train machine learning models  
âœ“ Build and train deep learning models  
âœ“ Perform NLP tasks with spaCy  
âœ“ Evaluate models comprehensively  
âœ“ Identify and mitigate biases  
âœ“ Debug and optimize code  
âœ“ Deploy models to production  
âœ“ Consider ethical implications  
âœ“ Communicate findings effectively  


## ğŸš€ Future Enhancements

1. **Advanced Models**
   - Vision Transformers for MNIST
   - BERT for sentiment analysis
   - Ensemble methods

2. **Improved Fairness**
   - TensorFlow Fairness Toolkit integration
   - Demographic parity metrics
   - Calibration analysis

3. **Better Deployment**
   - Docker containerization
   - Kubernetes orchestration
   - API with FastAPI/Flask

4. **Enhanced UI**
   - Real-time webcam input
   - Mobile app version
   - Multi-model comparison


## ğŸ“… Timeline

| Phase | Duration | Status |
|-------|----------|--------|
| Part 1 Theoretical | 2-3 hours | âœ“ Complete |
| Part 2 Practical | 4-5 hours | âœ“ Complete |
| Part 3 Ethics | 2-3 hours | âœ“ Complete |
| Bonus Deployment | 2-3 hours | âœ“ Complete |
| Documentation | 2 hours | âœ“ Complete |
| **Total** | **12-16 hours** | âœ“ **Complete** |


## ğŸ™ Acknowledgments

- TensorFlow and PyTorch teams for excellent frameworks
- Scikit-learn and spaCy communities
- MNIST dataset creators
- Kaggle for datasets and resources


**Last Updated:** [16-10-2025]  
**Version:** 1.0  
**Status:** Complete and Ready for Submission


## ğŸ“® Submission Details

**Submission Format:** GitHub Repository  
**Required Files:** All .py scripts, notebooks, requirements.txt, README.md  
**Report Format:** PDF (in reports/ folder)  
**Deployment:** Streamlit app (instructions in README)  

**GitHub Repository URL:** [Your Repository Link]  
**Live Demo (if deployed):** [Your Deployment Link]


**For any questions or clarifications, please refer to the comprehensive report in `AI_Tools_Assignment_Report.pdf` or check individual code comments.**

Happy learning! ğŸ‰
